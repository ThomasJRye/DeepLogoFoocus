{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_od_colab",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/satojkovic/DeepLogo2.git"
      ],
      "metadata": {
        "id": "-ehAPgQ2o6-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('DeepLogo2')"
      ],
      "metadata": {
        "id": "H8Jvk13spGHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIBaToFkmvR6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "# Clone the tensorflow models repository if it doesn't already exist\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Object Detection API\n",
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=.\n",
        "cp object_detection/packages/tf2/setup.py .\n",
        "python -m pip install ."
      ],
      "metadata": {
        "id": "0NAOd442m2p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import random\n",
        "import io\n",
        "import imageio\n",
        "import glob\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from IPython.display import display, Javascript\n",
        "from IPython.display import Image as IPyImage\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import colab_utils\n",
        "from object_detection.builders import model_builder\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "1hRJQEiam7F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_into_numpy_array(path):\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  im_width, im_height = image.size\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
      ],
      "metadata": {
        "id": "RbvyQsyck1V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_csv_into_numpy_array(csv, im_width, im_height):\n",
        "  # xmin,ymin,xmax,ymax\n",
        "  xmin, ymin, xmax, ymax = list(map(int, csv))\n",
        "  xmin /= im_width\n",
        "  ymin /= im_height\n",
        "  xmax /= im_width\n",
        "  ymax /= im_height\n",
        "  return np.array([[xmin, ymin, xmax, ymax]], dtype=np.float32)"
      ],
      "metadata": {
        "id": "gobxJ2l4vH8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_detections(image_np, boxes, classes, scores, category_index, figsize=(12, 16), image_name=None):\n",
        "  image_np_with_annotations = image_np.copy()\n",
        "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_with_annotations,\n",
        "      boxes, classes, scores, category_index,\n",
        "      use_normalized_coordinates=True,\n",
        "      min_score_thresh=0.8\n",
        "  )\n",
        "  if image_name:\n",
        "    plt.imsave(image_name, image_np_with_annotations)\n",
        "  else:\n",
        "    plt.imshow(image_np_with_annotations)"
      ],
      "metadata": {
        "id": "7J_NgD-F7m6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget http://image.ntua.gr/iva/datasets/flickr_logos/flickr_logos_27_dataset.tar.gz\n",
        "tar zxvf flickr_logos_27_dataset.tar.gz\n",
        "cd flickr_logos_27_dataset\n",
        "tar zxvf flickr_logos_27_dataset_images.tar.gz\n",
        "cd .."
      ],
      "metadata": {
        "id": "oBvbzfL4qOgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "python preproc_annot.py"
      ],
      "metadata": {
        "id": "KNjaBZKeqkRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_annot_csv = 'flickr_logos_27_dataset/flickr_logos_27_dataset_training_set_annotation_cropped.txt'\n",
        "train_img_dir = 'flickr_logos_27_dataset/flickr_logos_27_dataset_images'\n",
        "train_images_np = []\n",
        "gt_boxes = []\n",
        "gt_class_ids = []\n",
        "csvs = np.loadtxt(train_annot_csv, dtype=str, delimiter=',')\n",
        "for csv in tqdm(csvs):\n",
        "  img_fname = csv[0]\n",
        "  with tf.io.gfile.GFile(os.path.join(train_img_dir, img_fname), 'rb') as fid:\n",
        "    encoded_jpg = fid.read()\n",
        "  encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "  image = Image.open(encoded_jpg_io)\n",
        "  width, height = image.size\n",
        "\n",
        "  train_images_np.append(load_image_into_numpy_array(os.path.join(train_img_dir, img_fname)))\n",
        "  gt_boxes.append(convert_csv_into_numpy_array(csv[1:-1], width, height))\n",
        "  class_id = int(csv[-1])\n",
        "  gt_class_ids.append(class_id)\n",
        "\n",
        "plt.rcParams['axes.grid'] = False\n",
        "plt.rcParams['figure.figsize'] = [12, 5]\n",
        "\n",
        "for idx, train_image_np in enumerate(train_images_np[:6]):\n",
        "  plt.subplot(2, 3, idx + 1)\n",
        "  plt.imshow(train_image_np)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dZeHV2Haq6jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('train_images.npy', train_images_np)\n",
        "np.save('gt_boxes.npy', gt_boxes)\n",
        "np.save('gt_class_ids.npy', gt_class_ids)"
      ],
      "metadata": {
        "id": "TIiD8IuFJjEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\n",
        "  \"Adidas\", \"Apple\", \"BMW\", \"Citroen\", \"Cocacola\",\n",
        "  \"DHL\", \"Fedex\", \"Ferrari\", \"Ford\", \"Google\", \n",
        "  \"HP\", \"Heineken\", \"Intel\", \"McDonalds\", \"Mini\", \n",
        "  \"Nbc\", \"Nike\", \"Pepsi\", \"Porsche\", \"Puma\", \n",
        "  \"RedBull\", \"Sprite\", \"Starbucks\", \"Texaco\", \"Unicef\",\n",
        "  \"Vodafone\", \"Yahoo\"\n",
        "]"
      ],
      "metadata": {
        "id": "xv_1jHW9Fxoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_category_index(class_names):\n",
        "  category_index = {}\n",
        "  for i, class_name in enumerate(class_names):\n",
        "    category_index[i+1] = {'id': i + 1, 'name': class_name}\n",
        "  return category_index"
      ],
      "metadata": {
        "id": "Cog-RUxzGgm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "category_index = create_category_index(class_names)\n",
        "num_classes = len(category_index)"
      ],
      "metadata": {
        "id": "dzsHj2_3IeAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "pprint.pprint(num_classes)\n",
        "pprint.pprint(category_index)"
      ],
      "metadata": {
        "id": "Q5J6qJ5fIh8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert class label to one hot.\n",
        "# Convert everything to tensors.\n",
        "# The `label_id_offset` here shifts all classes by a certain number of indices;\n",
        "# we do this here so that the model receives one-hot labels where non-background\n",
        "# classes start counting at the zeroth index.\n",
        "# This is ordinarily just handled automatically in our training binaries, but we need to reproduce it here.\n",
        "label_id_offset = 1\n",
        "train_image_tensors = []\n",
        "gt_box_tensors = []\n",
        "gt_classes_one_hot_tensors = tf.one_hot(gt_class_ids, depth=num_classes)\n",
        "for (train_image_np, gt_box_np) in zip(train_images_np, gt_boxes):\n",
        "  train_image_tensors.append(\n",
        "      tf.expand_dims(tf.convert_to_tensor(train_image_np, dtype=tf.float32), axis=0)\n",
        "  )\n",
        "  gt_box_tensors.append(\n",
        "      tf.convert_to_tensor(gt_box_np, dtype=tf.float32)\n",
        "  )\n",
        "print('train_image_tensors[0]:', tf.shape(train_image_tensors[0]))\n",
        "print('gt_box_tensors[0]:', tf.shape(gt_box_tensors[0]))\n",
        "print('gt_classes_one_hot_tensors[0]:', tf.shape(gt_classes_one_hot_tensors[0]))\n",
        "print('Done prepping data')"
      ],
      "metadata": {
        "id": "srJ1k_Hy9bWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_scores = np.array([1.0], dtype=np.float32)\n",
        "\n",
        "plt.figure(figsize=(12, 15))\n",
        "for idx in range(5):\n",
        "  plt.subplot(2, 3, idx + 1)\n",
        "  plot_detections(\n",
        "      train_images_np[idx], gt_boxes[idx],\n",
        "      np.ones(shape=[gt_boxes[idx].shape[0]], dtype=np.int32),\n",
        "      dummy_scores, category_index\n",
        "  )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MLFcX1OiA1zM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the checkpoint and put it into models/research/object_detection/test_data/\n",
        "\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!tar -xf ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
        "!mv ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint models/research/object_detection/test_data/"
      ],
      "metadata": {
        "id": "o6Rf_jwHEQP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print('Building model and restoring weights for fine-tuning.', flush=True)\n",
        "pipeline_config = 'models/research/object_detection/configs/tf2/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8.config'\n",
        "checkpoint_path = 'models/research/object_detection/test_data/checkpoint/ckpt-0'\n",
        "\n",
        "# Load pipeling config and build a detection model\n",
        "#\n",
        "# Since we are working off of a COCO architecture which predicts 90\n",
        "# class slots by default, we override the `num_classes` field here to be just one\n",
        "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
        "model_config = configs['model']\n",
        "model_config.ssd.num_classes = num_classes\n",
        "model_config.ssd.freeze_batchnorm = True\n",
        "detection_model = model_builder.build(\n",
        "    model_config=model_config, is_training=True\n",
        ")\n",
        "\n",
        "# Define checkpoints for desired layers\n",
        "#\n",
        "# We will now isolate the layers of `detection_model` that you wish to reuse so that you can\n",
        "# restore the weights to just those layers.\n",
        "# 1. Define checkpoints for the box predictor\n",
        "# 2. Define checkpoints for the model, which will point to this box predictor checkpoint as well as the feature extraction layers\n",
        "# 3. Restore the checkpoint for desired layers\n",
        "fake_box_predictor = tf.compat.v2.train.Checkpoint(\n",
        "    _base_tower_layers_for_heads=detection_model._box_predictor._base_tower_layers_for_heads,\n",
        "    #_prediction_heads=detection_model._box_predictor._prediction_heads,\n",
        "    _box_prediction_heads=detection_model._box_predictor._box_prediction_head,\n",
        ")\n",
        "fake_model = tf.compat.v2.train.Checkpoint(\n",
        "    _feature_extractor=detection_model._feature_extractor,\n",
        "    _box_predictor=fake_box_predictor\n",
        ")\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=fake_model)\n",
        "ckpt.restore(checkpoint_path).expect_partial()\n",
        "\n",
        "# Run model through a dummy image so that variables are created\n",
        "image, shapes = detection_model.preprocess(tf.zeros([1, 640, 640, 3]))\n",
        "prediction_dict = detection_model.predict(image, shapes)\n",
        "_ = detection_model.postprocess(prediction_dict, shapes)\n",
        "print('Weights restored')"
      ],
      "metadata": {
        "id": "VqjEadc9Bu9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `detection_model` is SSDMetaArch object\n",
        "import pprint\n",
        "pprint.pprint(detection_model)\n",
        "pprint.pprint(vars(detection_model))"
      ],
      "metadata": {
        "id": "9AxwjhV6IZQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint.pprint(detection_model._box_predictor)\n",
        "pprint.pprint(vars(detection_model._box_predictor))"
      ],
      "metadata": {
        "id": "CxOMYoS_ZJ07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detection_model._box_predictor"
      ],
      "metadata": {
        "id": "QnRRSQXTZtsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training loop"
      ],
      "metadata": {
        "id": "qLcKHUI-g1fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.set_learning_phase(True)\n",
        "\n",
        "batch_size = 4\n",
        "learning_rate = 0.01\n",
        "num_batches = 100"
      ],
      "metadata": {
        "id": "YnmEFgrsa5Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the layers of `detection_model`\n",
        "for i, v in enumerate(detection_model.trainable_variables):\n",
        "  pprint.pprint('i: {}, name: {}, shape: {}, dtype: {}'.format(i, v.name, v.shape, v.dtype))"
      ],
      "metadata": {
        "id": "zMyBk12Rg3Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the prediction layers\n",
        "trainable_variables = detection_model.trainable_variables\n",
        "to_fine_tune = []\n",
        "prefixes_to_train = [\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead',\n",
        "  'WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead']\n",
        "for var in trainable_variables:\n",
        "  if any([var.name.startswith(prefix) for prefix in prefixes_to_train]):\n",
        "    to_fine_tune.append(var)"
      ],
      "metadata": {
        "id": "OlL9N08UiM18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up for fwd + bwd pass for a single train step\n",
        "def get_model_train_step_function(model, optimizer, vars_to_fine_tune):\n",
        "  @tf.function\n",
        "  def train_step_fn(image_tensors,\n",
        "                    groundtruth_boxes_list,\n",
        "                    groundtruth_classes_list):\n",
        "    shapes = tf.constant(batch_size * [[640, 640, 3]], dtype=tf.int32)\n",
        "    model.provide_groundtruth(\n",
        "        groundtruth_boxes_list=groundtruth_boxes_list,\n",
        "        groundtruth_classes_list=groundtruth_classes_list\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "      preprocessed_images = tf.concat(\n",
        "          [detection_model.preprocess(image_tensor)[0]\n",
        "           for image_tensor in image_tensors], axis=0\n",
        "      )\n",
        "      prediction_dict = model.predict(preprocessed_images, shapes)\n",
        "      losses_dict = model.loss(prediction_dict, shapes)\n",
        "      total_loss = losses_dict['Loss/localization_loss'] + losses_dict['Loss/classification_loss']\n",
        "      gradients = tape.gradient(total_loss, vars_to_fine_tune)\n",
        "      optimizer.apply_gradients(zip(gradients, vars_to_fine_tune))\n",
        "    return total_loss\n",
        "\n",
        "  return train_step_fn"
      ],
      "metadata": {
        "id": "aIXH9hDKlgxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "train_step_fn = get_model_train_step_function(detection_model, optimizer, to_fine_tune)\n",
        "\n",
        "print('Start fine-tuning', flush=True)\n",
        "for idx in range(num_batches):\n",
        "  all_keys = list(range(len(train_images_np)))\n",
        "  random.shuffle(all_keys)\n",
        "  example_keys = all_keys[:batch_size]\n",
        "\n",
        "  gt_boxes_list = [gt_box_tensors[key] for key in example_keys]\n",
        "  gt_classes_list = [gt_classes_one_hot_tensors[key] for key in example_keys]\n",
        "  image_tensors = [train_image_tensors[key] for key in example_keys]\n",
        "\n",
        "  total_loss = train_step_fn(image_tensors, gt_boxes_list, gt_classes_list)\n",
        "\n",
        "  if idx % 10 == 0:\n",
        "    print('batch ' + str(idx) + ' of ' + str(num_batches) + ', loss=' + str(total_loss.numpy()), flush=True)\n",
        "\n",
        "print('Done fine-tuning')"
      ],
      "metadata": {
        "id": "lNDw5w3QnZAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Test"
      ],
      "metadata": {
        "id": "fIJbhqgJHG9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_image_dir = 'models/research/object_detection/test_images/ducky/test'\n",
        "test_images_np = []\n",
        "for i in range(1, 50):\n",
        "  image_path = os.path.join(test_image_dir, 'out' + str(i) + '.jpg')\n",
        "  test_images_np.append(np.expand_dims(\n",
        "      load_image_into_numpy_array(image_path), axis=0)\n",
        "  )\n",
        "\n",
        "@tf.function\n",
        "def detect(input_tensor):\n",
        "  preprocessed_image, shapes = detection_model.preprocess(input_tensor)\n",
        "  prediction_dict = detection_model.predict(preprocessed_image, shapes)\n",
        "  return detection_model.postprocess(prediction_dict, shapes)\n",
        "\n",
        "# Note that the first frame will trigger tracing of the tf.function, which will\n",
        "# take some time, after which inference should be fast.\n",
        "label_id_offset = 1\n",
        "for i in range(len(test_images_np)):\n",
        "  input_tensor = tf.convert_to_tensor(test_images_np[i], dtype=np.float32)\n",
        "  detections = detect(input_tensor)\n",
        "\n",
        "  plot_detections(\n",
        "      test_images_np[i][0], detections['detection_boxes'][0].numpy(),\n",
        "      detections['detection_classes'][0].numpy().astype(np.uint32)\n",
        "      + label_id_offset,\n",
        "      detections['detection_scores'][0].numpy(),\n",
        "      category_index, figsize=(15, 20), image_name='gif_frame_' + ('%02d' % i) + \".jpg\"\n",
        "  )"
      ],
      "metadata": {
        "id": "BI-_vvBJpIL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "mJKXRgjUK3Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageio.plugins.freeimage.download()\n",
        "\n",
        "anim_file = 'duckies_test.gif'\n",
        "\n",
        "filenames = glob.glob('gif_frame_*.jpg')\n",
        "filenames = sorted(filenames)\n",
        "last = -1\n",
        "images = []\n",
        "for filename in filenames:\n",
        "  image = imageio.imread(filename)\n",
        "  images.append(image)\n",
        "\n",
        "imageio.mimsave(anim_file, images, 'GIF-FI', fps=5)\n",
        "display(IPyImage(open(anim_file, 'rb').read()))"
      ],
      "metadata": {
        "id": "2e47WLruJjdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-FDrCx6nKjdj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}